{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Sentiment Analysis Project using BERT Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BERT model\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "# download bert pretrained model\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased') # this model was trained on lowercase text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download Bert tokenizer\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# load Bert tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased',do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer Sequence [101, 3958, 27227, 2001, 1037, 13997, 11510, 102, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# input text\n",
    "\n",
    "text = \"Jim Henson was a puppeteer\"\n",
    "\n",
    "sent_id = tokenizer.encode(text,\n",
    "                        # add [CLS] and [SEP] tokens\n",
    "                        add_special_tokens = True,\n",
    "                        # specify maximum length \n",
    "                        max_length = 10,\n",
    "                        truncation = True,\n",
    "                        # add pad token to the right side of the token\n",
    "                        padding = 'max_length')\n",
    "\n",
    "# print integer sequence\n",
    "print(f\"Integer Sequence {sent_id}\")\n",
    "\n",
    "# 101 is [CLS] token in integer\n",
    "# 102 is [SEP] token in integer\n",
    "# last two 0's are the result of padding to make it max_length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: ['[CLS]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# converting integer back to text as we can see 6 tokens generated for 5 words\n",
    "\n",
    "print(\"Tokenized Text:\",tokenizer.convert_ids_to_tokens(sent_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode String [CLS] jim henson was a puppeteer [SEP] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# decode the tokenized text\n",
    "\n",
    "decode = tokenizer.decode(sent_id)\n",
    "print(\"Decode String {}\".format(decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Mask [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# mask to avoid performing attention on padding tokens\n",
    "# mask values : 1 is for that tokens that are NOT MASKED, 0 for MASKED tokens.\n",
    "\n",
    "att_mask = [int(tok > 0)for tok in sent_id]\n",
    "print(\"Attention Mask\",att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Understanding Input and Output***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3958, 27227,  2001,  1037, 13997, 11510,   102,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# convert list to tensors\n",
    "\n",
    "sent_id = torch.tensor(sent_id)\n",
    "att_mask = torch.tensor(att_mask)\n",
    "\n",
    "# reshaping tensor in the form of (batch,text length)\n",
    "\n",
    "sent_id = sent_id.unsqueeze(0)\n",
    "att_mask = att_mask.unsqueeze(0)\n",
    "\n",
    "# printing reshaped tensor\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass integer sequence to the Bert Model\n",
    "\n",
    "outputs = bert(sent_id,att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapre of last hidden states: torch.Size([1, 10, 768])\n",
      "Shapre of CLS hidden states: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# unpack the output of Bert model\n",
    "\n",
    "all_hidden_states = outputs[0]\n",
    "\n",
    "cls_hidden_state = outputs[1]\n",
    "\n",
    "print(\"Shapre of last hidden states:\",all_hidden_states.shape)\n",
    "\n",
    "print(\"Shapre of CLS hidden states:\",cls_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8767, -0.4109, -0.1220,  0.4494,  0.1945, -0.2698,  0.8316,  0.3127,\n",
       "          0.1178, -1.0000, -0.1561,  0.6677,  0.9891, -0.3451,  0.8812, -0.6753,\n",
       "         -0.3079, -0.5580,  0.4380, -0.4588,  0.5831,  0.9956,  0.4467,  0.2863,\n",
       "          0.3924,  0.6864, -0.7513,  0.9043,  0.9436,  0.8207, -0.6493,  0.3524,\n",
       "         -0.9919, -0.2295, -0.0742, -0.9936,  0.3698, -0.7558,  0.0792, -0.2218,\n",
       "         -0.8637,  0.4711,  0.9997, -0.4368,  0.0404, -0.3498, -1.0000,  0.2663,\n",
       "         -0.8711,  0.0508,  0.0505, -0.1634,  0.1716,  0.4363,  0.4330, -0.0333,\n",
       "         -0.0416,  0.2206, -0.2568, -0.6122, -0.5916,  0.2569, -0.2622, -0.9041,\n",
       "          0.3221, -0.2394, -0.2634, -0.3454, -0.0723,  0.0081,  0.8297,  0.2279,\n",
       "          0.1614, -0.6555, -0.2062,  0.3280, -0.4016,  1.0000, -0.0952, -0.9874,\n",
       "         -0.0400,  0.0717,  0.3675,  0.3373, -0.3710, -1.0000,  0.4479, -0.1722,\n",
       "         -0.9917,  0.2677,  0.4844, -0.2207, -0.3207,  0.3715, -0.2171, -0.2522,\n",
       "         -0.3071, -0.3161, -0.1988, -0.0860, -0.0114, -0.1982, -0.1799, -0.3221,\n",
       "          0.1751, -0.4442, -0.1570, -0.0434, -0.0893,  0.5717,  0.3112, -0.2900,\n",
       "          0.3305, -0.9430,  0.6061, -0.2984, -0.9873, -0.3956, -0.9926,  0.7857,\n",
       "         -0.1692, -0.2719,  0.9505,  0.5628,  0.2904, -0.1693,  0.1619, -1.0000,\n",
       "         -0.1696, -0.1534,  0.2513, -0.2857, -0.9846, -0.9638,  0.5565,  0.9200,\n",
       "          0.1805,  0.9995, -0.2122,  0.9391,  0.3246, -0.3937, -0.1248, -0.5209,\n",
       "          0.0519,  0.1141, -0.6463,  0.3529, -0.0322, -0.3837, -0.3796, -0.2830,\n",
       "          0.1280, -0.9191, -0.4201,  0.9145,  0.0713, -0.2455,  0.5212, -0.2642,\n",
       "         -0.3675,  0.8082,  0.2577,  0.2755, -0.0157,  0.3675, -0.3107,  0.4502,\n",
       "         -0.8224,  0.2841,  0.4360, -0.3193,  0.2164, -0.9851, -0.4444,  0.5759,\n",
       "          0.9878,  0.7531,  0.3384,  0.2003, -0.2602,  0.4695, -0.9561,  0.9855,\n",
       "         -0.1712,  0.2295,  0.1220, -0.1386, -0.8436, -0.3783,  0.8371, -0.3204,\n",
       "         -0.8457, -0.0473, -0.4219, -0.3593, -0.2187,  0.5282, -0.3149, -0.4375,\n",
       "         -0.0440,  0.9242,  0.9296,  0.7735, -0.3733,  0.3945, -0.9049, -0.2898,\n",
       "          0.2695,  0.2910,  0.1695,  0.9932, -0.3069, -0.1611, -0.8349, -0.9827,\n",
       "          0.1299, -0.8555, -0.0531, -0.6830,  0.3926,  0.2873, -0.1899,  0.2598,\n",
       "         -0.9201, -0.7455,  0.3943, -0.3955,  0.4015, -0.2341,  0.7593,  0.3421,\n",
       "         -0.6143,  0.5170,  0.8987,  0.1072, -0.6858,  0.6481, -0.2454,  0.8712,\n",
       "         -0.5958,  0.9936,  0.3404,  0.4972, -0.9452, -0.2347, -0.8748, -0.0154,\n",
       "         -0.1293, -0.5265,  0.4235,  0.4206,  0.3663,  0.7488, -0.4650,  0.9900,\n",
       "         -0.8695, -0.9701, -0.5203, -0.0900, -0.9914,  0.0978,  0.2844, -0.0424,\n",
       "         -0.4649, -0.4546, -0.9620,  0.8035,  0.2177,  0.9705, -0.0793, -0.7985,\n",
       "         -0.3436, -0.9537, -0.0035, -0.0945,  0.4291,  0.0391, -0.9602,  0.4497,\n",
       "          0.5135,  0.4913,  0.0608,  0.9948,  1.0000,  0.9810,  0.8865,  0.7961,\n",
       "         -0.9894, -0.5122,  1.0000, -0.8521, -1.0000, -0.9412, -0.6633,  0.3110,\n",
       "         -1.0000, -0.1468, -0.1235, -0.9465, -0.0891,  0.9796,  0.9700, -1.0000,\n",
       "          0.9324,  0.9259, -0.4503,  0.4591, -0.1785,  0.9819,  0.2285,  0.4423,\n",
       "         -0.2615,  0.4124, -0.5252, -0.8534,  0.0365, -0.0670,  0.8944,  0.1913,\n",
       "         -0.4782, -0.9402,  0.2293, -0.1581, -0.2440, -0.9604, -0.1924, -0.0555,\n",
       "          0.5484,  0.1915,  0.2038, -0.7367,  0.2698, -0.7307,  0.3715,  0.5640,\n",
       "         -0.9386, -0.5717,  0.3818, -0.2775,  0.1536, -0.9608,  0.9702, -0.3502,\n",
       "          0.1524,  1.0000,  0.3876, -0.9001,  0.2547,  0.1857,  0.0832,  1.0000,\n",
       "          0.3811, -0.9852, -0.4053,  0.2576, -0.3923, -0.4125,  0.9994, -0.1463,\n",
       "         -0.0428,  0.2818,  0.9899, -0.9923,  0.8351, -0.8563, -0.9634,  0.9617,\n",
       "          0.9268, -0.4225, -0.7369,  0.1318,  0.1107,  0.2294, -0.8914,  0.6082,\n",
       "          0.4665, -0.0720,  0.8555, -0.7973, -0.3478,  0.4201, -0.1762,  0.0761,\n",
       "          0.2823,  0.4571, -0.1350,  0.1190, -0.3509, -0.4039, -0.9556,  0.0262,\n",
       "          1.0000, -0.2164,  0.0569, -0.2296, -0.1003, -0.1827,  0.4036,  0.4715,\n",
       "         -0.3293, -0.8471, -0.0518, -0.8453, -0.9935,  0.6732,  0.2284, -0.1968,\n",
       "          0.9998,  0.5194,  0.2326,  0.1718,  0.7497, -0.0192,  0.4518, -0.0327,\n",
       "          0.9765, -0.3259,  0.3491,  0.7471, -0.3186, -0.3019, -0.5725,  0.0563,\n",
       "         -0.9206,  0.0572, -0.9589,  0.9565,  0.3109,  0.3348,  0.1635, -0.0619,\n",
       "          1.0000, -0.6020,  0.5309, -0.3723,  0.6636, -0.9851, -0.6789, -0.4312,\n",
       "         -0.1435, -0.0827, -0.2497,  0.1323, -0.9786, -0.0474, -0.0304, -0.9444,\n",
       "         -0.9927,  0.2508,  0.6172,  0.1679, -0.7980, -0.6078, -0.4906,  0.4646,\n",
       "         -0.1934, -0.9396,  0.5453, -0.3000,  0.4329, -0.3340,  0.4408, -0.2058,\n",
       "          0.8344,  0.1265, -0.0307, -0.2098, -0.8340,  0.7114, -0.7410,  0.0518,\n",
       "         -0.1481,  1.0000, -0.3100,  0.1461,  0.7011,  0.6334, -0.2857,  0.1618,\n",
       "          0.0966,  0.2955, -0.0981, -0.1832, -0.6208, -0.3013,  0.4337,  0.0283,\n",
       "         -0.2959,  0.7579,  0.4711,  0.3666, -0.0531,  0.0914,  0.9969, -0.2267,\n",
       "         -0.1165, -0.5533, -0.1262, -0.3575, -0.2124,  1.0000,  0.3679,  0.0604,\n",
       "         -0.9936, -0.2000, -0.9208,  0.9999,  0.8511, -0.8783,  0.5650,  0.2405,\n",
       "         -0.2859,  0.6935, -0.2598, -0.2655,  0.2893,  0.2862,  0.9774, -0.4575,\n",
       "         -0.9764, -0.5964,  0.3966, -0.9575,  0.9939, -0.5326, -0.2349, -0.4376,\n",
       "         -0.0250,  0.2574,  0.0274, -0.9762, -0.1582,  0.1821,  0.9811,  0.3014,\n",
       "         -0.3820, -0.9007, -0.1151,  0.3936, -0.0680, -0.9449,  0.9809, -0.9313,\n",
       "          0.2600,  1.0000,  0.3860, -0.5243,  0.2401, -0.4410,  0.3253, -0.1413,\n",
       "          0.5428, -0.9466, -0.2817, -0.3262,  0.4330, -0.2120, -0.2457,  0.7247,\n",
       "          0.2134, -0.3430, -0.6305, -0.1214,  0.4871,  0.7498, -0.2957, -0.1829,\n",
       "          0.1699, -0.1391, -0.9264, -0.4167, -0.2995, -0.9991,  0.6411, -1.0000,\n",
       "         -0.1510, -0.5473, -0.2219,  0.8075,  0.3862, -0.1392, -0.7206, -0.0710,\n",
       "          0.6995,  0.6656, -0.2889,  0.2902, -0.6951,  0.1622, -0.1298,  0.3182,\n",
       "          0.1694,  0.6526, -0.2735,  1.0000,  0.1370, -0.3043, -0.9189,  0.3041,\n",
       "         -0.2604,  1.0000, -0.7969, -0.9715,  0.2110, -0.5773, -0.7218,  0.2477,\n",
       "         -0.0304, -0.7015, -0.6577,  0.9111,  0.8219, -0.3693,  0.4537, -0.3062,\n",
       "         -0.3671,  0.0856,  0.1595,  0.9903,  0.2790,  0.8213, -0.2885, -0.0724,\n",
       "          0.9636,  0.2213,  0.6892,  0.2070,  1.0000,  0.3249, -0.8999,  0.2644,\n",
       "         -0.9700, -0.2610, -0.9228,  0.4016,  0.1170,  0.8570, -0.3587,  0.9672,\n",
       "          0.0667,  0.1108, -0.1840,  0.4711,  0.3127, -0.9391, -0.9892, -0.9908,\n",
       "          0.3962, -0.5013, -0.0640,  0.3811,  0.1530,  0.4712,  0.3781, -1.0000,\n",
       "          0.9466,  0.3529,  0.2077,  0.9735,  0.2019,  0.4726,  0.4248, -0.9892,\n",
       "         -0.9203, -0.3418, -0.2910,  0.6572,  0.5584,  0.8190,  0.4319, -0.4171,\n",
       "         -0.4697,  0.4653, -0.8583, -0.9940,  0.4802,  0.0740, -0.8986,  0.9559,\n",
       "         -0.4745, -0.1616,  0.4457,  0.1412,  0.8933,  0.8280,  0.4313,  0.2437,\n",
       "          0.6787,  0.9043,  0.8940,  0.9903, -0.2561,  0.6986, -0.0055,  0.3281,\n",
       "          0.6809, -0.9586,  0.1583,  0.0033, -0.2711,  0.3025, -0.1928, -0.9207,\n",
       "          0.5260, -0.2139,  0.5709, -0.2302,  0.1593, -0.4779, -0.1577, -0.7036,\n",
       "         -0.5208,  0.4676,  0.2335,  0.9372,  0.4775, -0.1995, -0.5655, -0.2336,\n",
       "          0.0798, -0.9315,  0.8288, -0.0946,  0.5294,  0.0223, -0.0744,  0.7821,\n",
       "          0.1236, -0.3705, -0.3959, -0.7528,  0.8145, -0.3204, -0.4786, -0.5135,\n",
       "          0.7306,  0.3208,  0.9981, -0.3959, -0.3492, -0.1118, -0.2872,  0.3596,\n",
       "         -0.1345, -1.0000,  0.2896,  0.2262,  0.1702, -0.3530,  0.1111, -0.0755,\n",
       "         -0.9565, -0.2658,  0.2530, -0.0490, -0.5834, -0.4616,  0.3937,  0.2329,\n",
       "          0.5620,  0.8138, -0.0288,  0.5621,  0.3811,  0.0852, -0.6049,  0.8452]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Data Preparation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tweet.csv\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',200)\n",
    "\n",
    "# read csv file\n",
    "\n",
    "tweets = pd.read_csv(r\"/Users/nick_mac/Desktop/Natural-Language-Processing/BERT-Project/data/Tweets.csv\")\n",
    "\n",
    "# print top 5 rows\n",
    "\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the dataframe\n",
    "\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10386                   @USAirways And cherry on top-flight 880 was on runway after we landed ON TIME for 45 mins. Still didn't get half the luggage.\n",
       "1462          @united you really screwed up dealing mechanical failure from Maui to San Francisco. Poor communication bad help in getting connections\n",
       "8271               @JetBlue That'd be nice! Hoping to rack up enough miles to take a trip to Seattle and enjoy a perfect latte in the city of coffee.\n",
       "10657        @USAirways It says to call. Before connecting, get song, dance about weather. Weather bad 3 days? Called for 2 days before. #wasteoftime\n",
       "5763     @SouthwestAir my sinuses had to contend with two painful landings rather than one, and we missed a preregistration window. Beyond frustrated\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample of tweets\n",
    "\n",
    "tweets['text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment class distribution\n",
    "\n",
    "tweets['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    0.626913\n",
       "neutral     0.211680\n",
       "positive    0.161407\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the proportion\n",
    "\n",
    "tweets['airline_sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9178, 3099, 2363]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the value counts to a list\n",
    "\n",
    "class_count = tweets['airline_sentiment'].value_counts().to_list()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Text Cleaning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    text = re.sub(r'http\\S+','',text)\n",
    "    tokens = text.split()\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform text cleaning\n",
    "\n",
    "tweets['clean_text'] = tweets['text'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned text and labels to the variable\n",
    "\n",
    "text = tweets['clean_text'].values\n",
    "labels = tweets['airline_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"plus you've added commercials to the experience... tacky.\",\n",
       "       \"i didn't today... must mean i need to take another trip!\",\n",
       "       'it\\'s really aggressive to blast obnoxious \"entertainment\" in your guests\\' faces &amp; they have little recourse',\n",
       "       \"and it's a really big bad thing about it\",\n",
       "       \"seriously would pay $30 a flight for seats that didn't have this playing. it's really the only bad thing about flying va\",\n",
       "       'yes, nearly every time i fly vx this “ear worm” won’t go away :)',\n",
       "       'really missed a prime opportunity for men without hats parody, there.',\n",
       "       \"well, i didn't…but now i do! :-d\",\n",
       "       \"it was amazing, and arrived an hour early. you're too good to me.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaned text\n",
    "\n",
    "text[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Preparing Input and Output Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing label encode\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# define label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit and transform\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'neutral' 'positive']\n",
      "[1 2 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# classes\n",
    "\n",
    "print(le.classes_)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Length of sentences')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the sequence of the tweets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = [len(i.split()) for i in text]\n",
    "\n",
    "plt.hist(num,bins= 30)\n",
    "\n",
    "plt.title(\"Length of sentences\")\n",
    "\n",
    "# the most of the tweets hasmax length of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define maximum length of a text\n",
    "\n",
    "max_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14640/14640 [00:00<00:00, 17979.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# library for progress bar\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# create an empty list to save integer sequence\n",
    "\n",
    "sent_id = []\n",
    "\n",
    "# iterate over each tweet\n",
    "\n",
    "for i in tqdm(range(len(text))):\n",
    "    encoded_sent = tokenizer.encode(text[i],\n",
    "                                    add_special_tokens = True,\n",
    "                                    max_length = max_len,\n",
    "                                    truncation = True,\n",
    "                                    padding = 'max_length')\n",
    "    \n",
    "    sent_id.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer Sequence [101, 2054, 2056, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print (\"Integer Sequence\",sent_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sent_id:\n",
    "    att_mask = [int(token_id) > 0 for token_id in sent]\n",
    "\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Training and Validation Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(sent_id,labels, random_state= 2018,test_size= 0.1,stratify=labels)\n",
    "\n",
    "train_masks, validation_masks, _,_ = train_test_split(attention_masks,labels,random_state= 2018,test_size= 0.1,stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Define Data loader***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
