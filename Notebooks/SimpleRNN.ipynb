{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "processed-personality",
   "metadata": {},
   "source": [
    "#### Simple RNN\n",
    "Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "material-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,SimpleRNN,Activation\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "passing-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating parameters for data load\n",
    "\n",
    "num_words = 30000\n",
    "max_length = 50\n",
    "test_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "editorial-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test data\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = reuters.load_data(num_words = num_words,maxlen = max_length,test_split = test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "static-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating a padding sequence and filling post sentences with zeros\n",
    "\n",
    "X_train = pad_sequences(X_train,padding = 'post')\n",
    "X_test = pad_sequences(X_test,padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "material-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  245  273  207  156   53   74  160   26   14   46  296   26   39\n",
      "    74 2979 3554   14   46 4689 4329   86   61 3499 4795   14   61  451\n",
      "  4329   17   12    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]]\n",
      "[[   1   53  160   26   14  134   26   39 3859 5024   14 3106 3719   86\n",
      "   134   19   11   14   83   32   11  180  183   32 4722 5924   14   32\n",
      "  6959 5532   17   12    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# checking whether padding implemented \n",
    "\n",
    "print(X_train[:1])\n",
    "print(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eight-monte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1595, 49)\n",
      "(399, 49)\n"
     ]
    }
   ],
   "source": [
    "# checking shape of dataset\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "indirect-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping our dataset\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0],X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "developing-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating y data set\n",
    "\n",
    "y_data = np.concatenate((y_train,y_test))\n",
    "y_data = to_categorical(y_data)\n",
    "y_train = y_data[:1595]\n",
    "y_test = y_data[1595:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "specified-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating rnn function\n",
    "\n",
    "def basic_rnn():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128,input_shape = (49,1),return_sequences = True)) # 1st Layer\n",
    "    model.add(SimpleRNN(128,return_sequences = False)) # 2nd Layer\n",
    "    model.add(Dense(46)) # Dense Layer\n",
    "    model.add(Activation('softmax')) # softmax for multi class prediction\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001) # creating customized adam optimizer\n",
    "    \n",
    "    # model compilation\n",
    "    model.compile(loss = \"categorical_crossentropy\",optimizer = adam,metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "defined-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating keras classifier\n",
    "\n",
    "model = KerasClassifier(build_fn = basic_rnn,epochs = 300,batch_size = 50,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "vulnerable-killing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 3s 35ms/step - loss: 2.1626 - accuracy: 0.5404\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.1326 - accuracy: 0.7189\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.1118 - accuracy: 0.7293\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.1035 - accuracy: 0.7370\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.1058 - accuracy: 0.7326\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.1140 - accuracy: 0.7293\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 1.0911 - accuracy: 0.7169\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.1320 - accuracy: 0.7100\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.1108 - accuracy: 0.7216\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.1200 - accuracy: 0.7072\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.1548 - accuracy: 0.7227\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.1395 - accuracy: 0.7243\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.1555 - accuracy: 0.7096\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.1050 - accuracy: 0.7272\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.1179 - accuracy: 0.7151\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.0724 - accuracy: 0.7120\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.1926 - accuracy: 0.6964\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.0957 - accuracy: 0.7159\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.0817 - accuracy: 0.7211\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.0157 - accuracy: 0.7350\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.0981 - accuracy: 0.7284\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.0781 - accuracy: 0.7299\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.1276 - accuracy: 0.6872\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.1063 - accuracy: 0.7226\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.1161 - accuracy: 0.7013\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.0874 - accuracy: 0.7055\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.0631 - accuracy: 0.7081\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.9626 - accuracy: 0.7541\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.0104 - accuracy: 0.7341\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.0970 - accuracy: 0.6984\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.0098 - accuracy: 0.7233\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.0736 - accuracy: 0.7017\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.0110 - accuracy: 0.7157\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.0101 - accuracy: 0.7369\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9968 - accuracy: 0.7294\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.0037 - accuracy: 0.7267\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9643 - accuracy: 0.7296\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.9910 - accuracy: 0.7380\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.0117 - accuracy: 0.7327\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.9531 - accuracy: 0.7347\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.9714 - accuracy: 0.7302\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9926 - accuracy: 0.7249\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.9774 - accuracy: 0.7250\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9779 - accuracy: 0.7249\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9878 - accuracy: 0.7210\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9953 - accuracy: 0.7278\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.9404 - accuracy: 0.7273\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9384 - accuracy: 0.7382\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.9062 - accuracy: 0.7400\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9460 - accuracy: 0.7372\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9027 - accuracy: 0.7423\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.0029 - accuracy: 0.7132\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.9283 - accuracy: 0.7408\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.9678 - accuracy: 0.7277\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.9669 - accuracy: 0.7354\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 1.0050 - accuracy: 0.7200\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9496 - accuracy: 0.7287\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9606 - accuracy: 0.7370\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9433 - accuracy: 0.7287\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.9665 - accuracy: 0.7235\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9373 - accuracy: 0.7333\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 1.0638 - accuracy: 0.6988\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.0123 - accuracy: 0.7175\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.0001 - accuracy: 0.7170\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9352 - accuracy: 0.7340\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9704 - accuracy: 0.7413\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9351 - accuracy: 0.7363\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9274 - accuracy: 0.7263\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8976 - accuracy: 0.7520\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9410 - accuracy: 0.7441\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9244 - accuracy: 0.7326\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8774 - accuracy: 0.7483\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8523 - accuracy: 0.7576\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.0562 - accuracy: 0.7202\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9401 - accuracy: 0.7483\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9310 - accuracy: 0.7336\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9606 - accuracy: 0.7284\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8889 - accuracy: 0.7441\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.8810 - accuracy: 0.7458\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8611 - accuracy: 0.7622\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8385 - accuracy: 0.7557\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8573 - accuracy: 0.7503\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9276 - accuracy: 0.7045\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.8352 - accuracy: 0.7615\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.8065 - accuracy: 0.7442\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8064 - accuracy: 0.7550\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8620 - accuracy: 0.7333\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8654 - accuracy: 0.7423\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.8536 - accuracy: 0.7502\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 1.0795 - accuracy: 0.7148\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9552 - accuracy: 0.7237\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.9430 - accuracy: 0.7353\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 1.0442 - accuracy: 0.6989\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.9695 - accuracy: 0.7243\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.0475 - accuracy: 0.6891\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.9818 - accuracy: 0.7085\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.0222 - accuracy: 0.7113\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.9189 - accuracy: 0.7198\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.9020 - accuracy: 0.7381\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.9490 - accuracy: 0.7201\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.9165 - accuracy: 0.7268\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.9426 - accuracy: 0.7210\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.9283 - accuracy: 0.7345\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8304 - accuracy: 0.7415\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.8764 - accuracy: 0.7324\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.8724 - accuracy: 0.7359\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8635 - accuracy: 0.7326\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8673 - accuracy: 0.7395\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8924 - accuracy: 0.7266\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.8946 - accuracy: 0.7222\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.8732 - accuracy: 0.7329\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.8607 - accuracy: 0.7309\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.8719 - accuracy: 0.7311\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.8644 - accuracy: 0.7366\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.8952 - accuracy: 0.7207\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.8956 - accuracy: 0.7255\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.7797 - accuracy: 0.7680\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.8595 - accuracy: 0.7341\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.8749 - accuracy: 0.7350\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.8498 - accuracy: 0.7315\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.8131 - accuracy: 0.7402\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.8277 - accuracy: 0.7362\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7659 - accuracy: 0.7700\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.8612 - accuracy: 0.7325\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8281 - accuracy: 0.7465\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7757 - accuracy: 0.7670\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7863 - accuracy: 0.7623\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7982 - accuracy: 0.7506\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7884 - accuracy: 0.7607\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8144 - accuracy: 0.7377\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.8297 - accuracy: 0.7536\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7763 - accuracy: 0.7571\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7644 - accuracy: 0.7632\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7693 - accuracy: 0.7700\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8089 - accuracy: 0.7592\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7621 - accuracy: 0.7751\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7730 - accuracy: 0.7695\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7507 - accuracy: 0.7796\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.7620 - accuracy: 0.7587\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7782 - accuracy: 0.7695\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7936 - accuracy: 0.7524\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.8380 - accuracy: 0.7250\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7635 - accuracy: 0.7649\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7807 - accuracy: 0.7561\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7217 - accuracy: 0.7839\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7544 - accuracy: 0.7692\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7218 - accuracy: 0.7893\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.8029 - accuracy: 0.7401\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6842 - accuracy: 0.7922\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7500 - accuracy: 0.7631\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7299 - accuracy: 0.7643\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7473 - accuracy: 0.7673\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7321 - accuracy: 0.7769\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7343 - accuracy: 0.7758\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.6881 - accuracy: 0.7816\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7061 - accuracy: 0.7810\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7455 - accuracy: 0.7919\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.9542 - accuracy: 0.7229\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.8654 - accuracy: 0.7309\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.8220 - accuracy: 0.7408\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.8003 - accuracy: 0.7451\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7548 - accuracy: 0.7720\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7620 - accuracy: 0.7691\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.7637 - accuracy: 0.7656\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7280 - accuracy: 0.7770\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7580 - accuracy: 0.7619\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7316 - accuracy: 0.7753\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7732 - accuracy: 0.7579\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.8174 - accuracy: 0.7384\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7672 - accuracy: 0.7530\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7253 - accuracy: 0.7712\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.7194 - accuracy: 0.7808\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.6902 - accuracy: 0.7763\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7241 - accuracy: 0.7559\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6994 - accuracy: 0.7806\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.7354 - accuracy: 0.7558\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7166 - accuracy: 0.7690\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7067 - accuracy: 0.7791\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6453 - accuracy: 0.7978\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6567 - accuracy: 0.7827\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6338 - accuracy: 0.7955\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7018 - accuracy: 0.7794\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6896 - accuracy: 0.7747\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6488 - accuracy: 0.7919\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.8173 - accuracy: 0.7492\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.0289 - accuracy: 0.7165\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.1199 - accuracy: 0.7202\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.9894 - accuracy: 0.7271\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.8407 - accuracy: 0.7498\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.8335 - accuracy: 0.7485\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7493 - accuracy: 0.7683\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.7748 - accuracy: 0.7674\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6863 - accuracy: 0.7716\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.7773 - accuracy: 0.7536\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.8780 - accuracy: 0.7384\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7540 - accuracy: 0.7637\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7166 - accuracy: 0.7813 0s - loss: 0.7078 - accura\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.7107 - accuracy: 0.7721\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.6735 - accuracy: 0.7956\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6910 - accuracy: 0.7896\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6495 - accuracy: 0.8006\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6361 - accuracy: 0.8059\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.6444 - accuracy: 0.7864\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6889 - accuracy: 0.7623\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7947 - accuracy: 0.7568\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.7844 - accuracy: 0.7593\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7014 - accuracy: 0.7937\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.6592 - accuracy: 0.7927\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.6877 - accuracy: 0.7903\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6337 - accuracy: 0.8023\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6511 - accuracy: 0.8071\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6424 - accuracy: 0.7931\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.6732 - accuracy: 0.7687\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6308 - accuracy: 0.7936\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6824 - accuracy: 0.7763\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7409 - accuracy: 0.7654\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.6682 - accuracy: 0.7851\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.6133 - accuracy: 0.7976\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6102 - accuracy: 0.8048\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.5933 - accuracy: 0.7886\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6564 - accuracy: 0.7801\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.5551 - accuracy: 0.8236\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.6222 - accuracy: 0.7998\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.6387 - accuracy: 0.7785\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.6338 - accuracy: 0.7856\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.6451 - accuracy: 0.7724\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7059 - accuracy: 0.7552\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6381 - accuracy: 0.7848\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6302 - accuracy: 0.7849\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6087 - accuracy: 0.7892\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.6048 - accuracy: 0.7831\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.5505 - accuracy: 0.8099\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5089 - accuracy: 0.8254\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.5230 - accuracy: 0.8300\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.5791 - accuracy: 0.8022\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.5844 - accuracy: 0.8033\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5728 - accuracy: 0.8029\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5271 - accuracy: 0.8130\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5487 - accuracy: 0.8154\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.5409 - accuracy: 0.8196\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.9693 - accuracy: 0.6883\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7924 - accuracy: 0.7439\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.9191 - accuracy: 0.6928\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.7704 - accuracy: 0.7475\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.7486 - accuracy: 0.7553\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7395 - accuracy: 0.7459\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6590 - accuracy: 0.7672\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.5870 - accuracy: 0.7890\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7433 - accuracy: 0.7508\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.5952 - accuracy: 0.7866\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5574 - accuracy: 0.7911\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.6057 - accuracy: 0.7790\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7619 - accuracy: 0.7375\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.6333 - accuracy: 0.7898\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6745 - accuracy: 0.7756\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.5589 - accuracy: 0.8160\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5464 - accuracy: 0.8229\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5527 - accuracy: 0.8114\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.7815 - accuracy: 0.7813\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.7680 - accuracy: 0.7375\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.6710 - accuracy: 0.7568\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6666 - accuracy: 0.7577\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6437 - accuracy: 0.7639\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5917 - accuracy: 0.7940\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5397 - accuracy: 0.8097\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.5833 - accuracy: 0.8011\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.6124 - accuracy: 0.7975\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.6075 - accuracy: 0.7993\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5401 - accuracy: 0.8123\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5553 - accuracy: 0.8065\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5494 - accuracy: 0.8123\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5588 - accuracy: 0.8113\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7495 - accuracy: 0.7752\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.6307 - accuracy: 0.7857\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5443 - accuracy: 0.8201\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.5324 - accuracy: 0.8164\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.5511 - accuracy: 0.8013\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5572 - accuracy: 0.8128\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5145 - accuracy: 0.8306\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.4978 - accuracy: 0.8246\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5077 - accuracy: 0.8443\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5215 - accuracy: 0.8245\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.5883 - accuracy: 0.7867\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5074 - accuracy: 0.8119\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.4952 - accuracy: 0.8086\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5111 - accuracy: 0.8226\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5146 - accuracy: 0.8214\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5475 - accuracy: 0.8000\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.4953 - accuracy: 0.8176\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.5027 - accuracy: 0.8243\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5701 - accuracy: 0.8066\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.7469 - accuracy: 0.7501\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.5514 - accuracy: 0.8030\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.5662 - accuracy: 0.7941\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.5134 - accuracy: 0.8245\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.5310 - accuracy: 0.8020\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5348 - accuracy: 0.8230\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5535 - accuracy: 0.7976\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.4795 - accuracy: 0.8160\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.5039 - accuracy: 0.8302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb712d0280>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "devoted-lesson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_ = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "threatened-rapid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3,  3,  3,  3,  3,  4,  4,  3,  3,  3,  3,  3, 45,  3,  3,\n",
       "        3,  3,  3,  3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3, 24,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  3,  3,\n",
       "        3,  3,  4,  3,  3,  3,  3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  4,  3,  3,  3,  3,  3,  4,  3,  3,  4,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  4,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  4,  4,  4,  3,  3,  3,  3,  3,  3, 19,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3, 19,  3,  3,  3,  3,  3,  3, 19,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  1,  3,\n",
       "        3,  3,  4,  3,  3,  4,  3,  1,  3,  3,  3,  4,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  4,  4,  3,  1,  3,  3,  3,  4,  3,  3,\n",
       "        3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  4, 19, 10,  3,  3,  3,  4,\n",
       "        3,  3,  2,  3,  3,  3,  8,  3,  3,  3,  3,  3,  4,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  4,  4, 24, 19,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  1,  3,  3,  3,  3,  3,  3,  3, 24,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3, 21,  3,  3,  3,  3,  4,  3,  3,  3,  9,  3,  3,  3,  3,\n",
       "        3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  2,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  4,  3,  3,  3,  1,  3,  3,  3,  3,  3,\n",
       "        3,  4,  3,  3,  3,  3,  3,  3,  3,  4,  3,  3,  3,  4,  4,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        4,  3,  3,  3,  4,  3,  3,  3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "funded-paradise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 40,  3,  4,  3, 20,  3,  3, 16,  3,  3,  3,  3,  3,  4,  3,  3,\n",
       "        3,  1,  3,  3, 18,  3,  3,  3,  3,  3, 11,  3,  3,  3,  3,  3, 18,\n",
       "        3,  3,  3,  3,  3,  4,  3,  3,  3,  3,  3,  1,  3,  3,  3,  3, 20,\n",
       "        3,  3,  3,  3,  6,  3,  3,  3,  3,  3,  3,  3, 26,  4,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  4,  3,  4,  3,  3,  3,  4,  3,  4,  3,  3,  4,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3, 20,  0,  3,  3,  4,  3,  3,  3,  3,  3,\n",
       "        4,  3,  3,  3,  4,  4,  4, 12,  3,  3,  3,  3,  1,  3,  4,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  4, 20, 32,  3,  3,  3,  3,  3,  4,  3,\n",
       "        3,  3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4, 24,  3,\n",
       "        3,  3,  4,  3,  6, 12,  3,  4,  0,  3,  3,  4,  3,  3,  3,  4,  3,\n",
       "        4,  3,  3, 25,  3,  3,  4,  4, 40,  3,  2,  3,  3,  4,  4,  3,  3,\n",
       "        4,  3,  3,  3,  3,  3,  4,  3,  3,  3,  6, 20,  8,  3,  3,  3,  4,\n",
       "        3,  3, 19,  3,  3,  3,  8,  3,  3,  3,  3,  3, 16,  4,  3,  3,  3,\n",
       "        3,  3,  4, 20,  3, 19, 13,  4, 24,  3,  3,  3,  3,  4,  3,  3,  3,\n",
       "        3,  3,  3, 24,  3,  3,  4,  3,  3,  3,  3,  4,  3,  1,  3,  3,  3,\n",
       "        3,  3,  3,  4,  3,  3,  3,  4,  4,  3,  3,  3,  4,  3,  3,  3,  3,\n",
       "        3, 10,  4,  3,  1,  4, 20,  3,  1,  3,  3,  3,  3,  3,  3,  3,  4,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3, 19, 13,  3,  3,  3,  3, 16,  4,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  3,  3,  3,  3,  3,\n",
       "        3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4, 23,  3,  3,\n",
       "        3,  3,  4,  3,  3,  3,  3,  3, 24,  3,  3,  4,  4,  3, 19,  3,  3,\n",
       "       10, 16,  3,  3,  2,  3,  3,  3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "french-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "\n",
    "print(accuracy_score(y_test_,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
