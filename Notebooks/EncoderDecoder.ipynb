{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo1hSukD5ZL6"
      },
      "source": [
        "Encoder Decoder Language Translator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwy_mlC_5Xhr"
      },
      "source": [
        "# importing important libraries\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,LSTM,Dense\n",
        "import numpy as np"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhzky9Vy5yeP"
      },
      "source": [
        "# importing Dataset\n",
        "\n",
        "# Batch size for training\n",
        "batch_s = 64 \n",
        "\n",
        "# number of epochs to train our model\n",
        "epochs = 25\n",
        "\n",
        "# Latent dimensionality of encoding space\n",
        "latent_dimension = 256\n",
        "\n",
        "# number of samples to train\n",
        "number_samples = 10000\n",
        "\n",
        "# dataset\n",
        "data_path = '/content/fra.txt'"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHW24dw17j-K",
        "outputId": "f93021b4-2fff-4353-ec65-53210854c4ec"
      },
      "source": [
        "# vectorize the data\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path,'r',encoding='utf-8') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(number_samples,len(lines) - 1)]:\n",
        "  input_text,target_text,_ = line.split('\\t') # splitting the english and french seperately\n",
        "  target_text  = '\\t' + target_text + '\\n' # creating taget text which is french in this case\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "\n",
        "  for char in input_text:\n",
        "    if char not in input_characters:\n",
        "      input_characters.add(char)\n",
        "    \n",
        "  for char in target_text:\n",
        "    if char not in target_characters:\n",
        "      target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_len = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_len = max([len(txt) for txt in target_texts])\n",
        "print('Number of sample:',len(input_texts))\n",
        "print('Number of unique token:',num_encoder_tokens)\n",
        "print('Number of unique output:',num_decoder_tokens)\n",
        "print('Max seq length for input:',max_encoder_seq_len)\n",
        "print('Max seq length for output:',max_decoder_seq_len)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sample: 10000\n",
            "Number of unique token: 70\n",
            "Number of unique output: 93\n",
            "Max seq length for input: 16\n",
            "Max seq length for output: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CtJPrZJ-MlV"
      },
      "source": [
        "# generating corresponding numerical value\n",
        "\n",
        "input_token_index = dict([(char,i) for i,char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char,i) for i,char in enumerate(target_characters)])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mawK51Y-OrN"
      },
      "source": [
        "# creating zero matrixes\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts),max_encoder_seq_len,num_encoder_tokens),dtype = 'float32')\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype = 'float32')\n",
        "\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype = 'float32')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Sm61xrpUqH"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EUcrulYcW7v"
      },
      "source": [
        "# input Sequence\n",
        "\n",
        "encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
        "encoder = LSTM(latent_dimension,return_state=True)\n",
        "encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h,state_c]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmhyNF_feC4O"
      },
      "source": [
        "# setup decoder\n",
        "\n",
        "decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dimension,return_sequences=True,return_state=True)\n",
        "decoder_outputs,_,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens,activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9iMA6UweHiI"
      },
      "source": [
        "# defining the model\n",
        "\n",
        "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCUPxpbbhv1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22a46b5-5839-44c8-cbbb-2c59a5935d75"
      },
      "source": [
        "# Fitting the model\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit([encoder_input_data,decoder_input_data],decoder_target_data,\n",
        "          batch_size = batch_s,epochs = epochs,validation_split=0.2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "125/125 [==============================] - 9s 43ms/step - loss: 1.5186 - accuracy: 0.6948 - val_loss: 1.0663 - val_accuracy: 0.6992\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.9103 - accuracy: 0.7540 - val_loss: 0.8672 - val_accuracy: 0.7616\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.7166 - accuracy: 0.8010 - val_loss: 0.7457 - val_accuracy: 0.7852\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.6263 - accuracy: 0.8185 - val_loss: 0.6650 - val_accuracy: 0.8042\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.5647 - accuracy: 0.8348 - val_loss: 0.6330 - val_accuracy: 0.8144\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.5246 - accuracy: 0.8459 - val_loss: 0.5876 - val_accuracy: 0.8251\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4882 - accuracy: 0.8557 - val_loss: 0.5662 - val_accuracy: 0.8328\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4656 - accuracy: 0.8619 - val_loss: 0.5414 - val_accuracy: 0.8399\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4419 - accuracy: 0.8680 - val_loss: 0.5237 - val_accuracy: 0.8457\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4248 - accuracy: 0.8727 - val_loss: 0.5106 - val_accuracy: 0.8480\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4063 - accuracy: 0.8786 - val_loss: 0.4955 - val_accuracy: 0.8527\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3922 - accuracy: 0.8823 - val_loss: 0.4905 - val_accuracy: 0.8542\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3770 - accuracy: 0.8866 - val_loss: 0.4790 - val_accuracy: 0.8578\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3619 - accuracy: 0.8916 - val_loss: 0.4682 - val_accuracy: 0.8617\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3498 - accuracy: 0.8953 - val_loss: 0.4645 - val_accuracy: 0.8630\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3336 - accuracy: 0.8993 - val_loss: 0.4609 - val_accuracy: 0.8637\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3249 - accuracy: 0.9024 - val_loss: 0.4558 - val_accuracy: 0.8663\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3141 - accuracy: 0.9057 - val_loss: 0.4511 - val_accuracy: 0.8672\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3013 - accuracy: 0.9091 - val_loss: 0.4487 - val_accuracy: 0.8684\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2936 - accuracy: 0.9112 - val_loss: 0.4457 - val_accuracy: 0.8703\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2798 - accuracy: 0.9156 - val_loss: 0.4454 - val_accuracy: 0.8707\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2700 - accuracy: 0.9190 - val_loss: 0.4455 - val_accuracy: 0.8706\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2625 - accuracy: 0.9207 - val_loss: 0.4460 - val_accuracy: 0.8715\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2537 - accuracy: 0.9237 - val_loss: 0.4443 - val_accuracy: 0.8720\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2464 - accuracy: 0.9252 - val_loss: 0.4466 - val_accuracy: 0.8729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8454d9fa10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeh1yR8TqRvF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}